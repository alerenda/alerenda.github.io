<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Alessandro  Renda


</title>
<meta name="description" content="Research Fellow @ University of Trieste
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://github.com/alerenda/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>







    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
        
          
        
          
        
          
        
          
        
          
        
          
            
              <!-- Other normal pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">
                  publications
                  
                </a>
              </li>
            
          
        
          
            
              <!-- Teaching dropdown -->
              <li class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="/teaching/" id="teachingDropdown">
                  teaching
                </a>
                <div class="dropdown-menu" aria-labelledby="teachingDropdown">
                  <a class="dropdown-item" href="/teaching/fondamenti/">Fondamenti di Informatica</a>
                  <a class="dropdown-item" href="/teaching/cybersecurity/">Cybersecurity Lab</a>
                </div>
              </li>
            
          
        
          
            
              <!-- Other normal pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/talks/">
                  talks
                  
                </a>
              </li>
            
          
        
          
            
              <!-- Other normal pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">
                  projects
                  
                </a>
              </li>
            
          
        
          
            
              <!-- Other normal pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/activity/">
                  activity
                  
                </a>
              </li>
            
          
        
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Alessandro</span>  Renda
    </h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/ts.jpg">
      
      
        <div class="address">
          <p>Dept. of Engineering and Architecture</p> <p>University of Trieste</p> <p>Via Alfonso Valerio 6/1</p> <p>34127 Trieste TS, Italy</p>

        </div>
      
    </div>
    

    <div class="clearfix">
      <p>I’m a <strong>research fellow</strong> at the <a href="https://www.units.it" target="_blank">University of Trieste</a>, working at the <a href="https://dia.units.it/" target="_blank">Department of Engineering and Architecture (DIA)</a>.</p>

<p>My research interests include explainable artificial intelligence and federated learning, machine learning algorithms for data streams, applications of deep learning methodologies and web/ social mining.</p>

<p>Previously, I was a research fellow at the <a href="https://www.unipi.it" target="_blank">University of Pisa</a>, working at the <a href="https://www.dii.unipi.it" target="_blank">Department of Information Engineering (DII)</a> as a member of the <a href="http://ai.dii.unipi.it/" target="_blank">Artificial Intelligence-DII (AI-DII)</a> LAB.
I received the M.Sc. degree in Biomedical Engineering from the University of Pisa in 2017 and the Ph.D. degree in Smart Computing jointly awarded by the Universities of Florence, Pisa and Siena, in 2021, with a dissertation titled “<a href="https://flore.unifi.it/handle/2158/1235915#.YQkjgEDOPb0" target="_blank">Algorithms and Techniques for Data Stream Mining</a>” under the supervision of Prof. <a href="http://www.iet.unipi.it/a.bechini/BechiniHome.html" target="_blank">Alessio Bechini</a>.</p>

	  To get in touch, contact me via email: <a href="mailto:alessandro.renda@dia.units.it">alessandro.renda@dia.units.it</a>
    </div>

    

    
      <div class="publications">
  <h2>selected publications</h2>
  <p>whole list <a href="publications">here</a></p>
  
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">TAI</abbr>
    
  
  </div>

  <div id="tai2024" class="col-sm-8">
    
      <div class="title">Federated c-means and Fuzzy c-means Clustering Algorithms for Horizontally and Vertically Partitioned Data</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.it/citations?user=dasDbcAAAAAJ&hl=it" target="_blank">Bárcena, J. L. Corcuera</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.it/citations?hl=it&user=_EkQr2QAAAAJ" target="_blank">Marcelloni, F.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.it/citations?user=13nYgdUAAAAJ&hl=it" target="_blank">Renda, A.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.it/citations?user=ooYOGP4AAAAJ&hl=it" target="_blank">Bechini, A.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://scholar.google.it/citations?user=HCgZqXEAAAAJ&hl=it" target="_blank">Ducange, P.</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Artificial Intelligence</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://ieeexplore.ieee.org/document/10595840" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/tai2024" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/Unipisa/FederatedClustering" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Federated clustering lets multiple data owners collaborate in discovering patterns from distributed data without violating privacy requirements. The federated versions of traditional clustering algorithms proposed so far are, however, “lossy” since they fail to identify exactly the same clusters as the original versions executed on the merged data stored in a centralized server, as would happen if no privacy constraint occurred. In this paper, we propose federated procedures for losslessly executing the C-Means (CM) and the Fuzzy C-Means (FCM) algorithms in both horizontally and vertically partitioned data scenarios, while preserving data privacy. We formally prove that the proposed federated procedures identify the same clusters determined by applying the algorithms to the union of all local data. Further, we present an extensive experimental analysis for characterizing the behavior of the proposed approach in a typical federated learning scenario, that is, as the fraction of participants in the federation changes. We focus on the federated FCM and the horizontally partitioned data, which is the most interesting scenario. We show that the proposed procedure is effective and is able to achieve competitive performance with respect to two recently proposed versions of federated FCM for horizontally partitioned data.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">tai2024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bárcena, J. L. Corcuera and Marcelloni, F. and Renda, A. and Bechini, A. and Ducange, P.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Federated c-means and Fuzzy c-means Clustering Algorithms for Horizontally and Vertically Partitioned Data}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1–15}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{TAI}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TAI.2024.3426408}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/10595840}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/10595840}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{tai2024}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/Unipisa/FederatedClustering}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">order</span> <span class="p">=</span> <span class="s">{2024-07}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Daole2025" class="col-sm-8">
    
      <div class="title">Security Threats to Explainable Classifiers in Federated Learning</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.it/citations?user=yNletAoAAAAJ&hl=it" target="_blank">Daole, M.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.it/citations?user=HCgZqXEAAAAJ&hl=it" target="_blank">Ducange, P.</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Herrera, F.,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.it/citations?hl=it&user=_EkQr2QAAAAJ" target="_blank">Marcelloni, F.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.it/citations?user=13nYgdUAAAAJ&hl=it" target="_blank">Renda, A.</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Rodríguez-Barroso, N.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2025 International Joint Conference on Neural Networks (IJCNN)</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://doi.org/10.1109/IJCNN64981.2025.11227961" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/daole2025.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The decentralized nature of federated learning (FL) poses critical challenges related to security: Clients participating in the process may not necessarily be trustworthy and could engage in adversarial attacks, potentially undermining the integrity and reliability of the global machine learning model. Security concerns have been extensively investigated in traditional FL, where collaboratively learned models are typically deep neural networks. However, this class of models does not meet the requirement of explainability, which is considered essential for the trustworthiness of AI systems. In this work, we present an analysis on security threats to FL of explainable models, namely fuzzy rule-based classifiers (FRBCs). We outline the types of attacks a malicious client may implement, and assess, through a preliminary experimental analysis, the impact they have on FL of FRBCs in terms of global model performance. We also compare these findings with the effects of the same or similar well-established attacks in traditional FL of neural network models. Finally, we provide insights to improve the security of FRBCs learned in a federated fashion.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Daole2025</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Daole, M. and Ducange, P. and Herrera, F. and Marcelloni, F. and Renda, A. and Rodríguez-Barroso, N.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2025 International Joint Conference on Neural Networks (IJCNN)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Security Threats to Explainable Classifiers in Federated Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-8}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Fuzzy logic;Degradation;Analytical models;Privacy;Federated learning;Closed box;Artificial neural networks;Robustness;Security;Federated Learning;Explainable Artificial Intelligence;Fuzzy Rule-based Classifiers;Security}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IJCNN64981.2025.11227961}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/IJCNN64981.2025.11227961}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{daole2025.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">INFFUS</abbr>
    
  
  </div>

  <div id="inffus2025" class="col-sm-8">
    
      <div class="title">Increasing trust in AI through privacy preservation and model explainability: Federated Learning of Fuzzy Regression Trees</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.it/citations?user=dasDbcAAAAAJ&hl=it" target="_blank">Bárcena, J. L. Corcuera</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.it/citations?user=HCgZqXEAAAAJ&hl=it" target="_blank">Ducange, P.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.it/citations?hl=it&user=_EkQr2QAAAAJ" target="_blank">Marcelloni, F.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://scholar.google.it/citations?user=13nYgdUAAAAJ&hl=it" target="_blank">Renda, A.</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Information Fusion</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://www.sciencedirect.com/science/article/pii/S1566253524003762" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/inffus2025.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/Unipisa/FederatedFuzzyRegressionTree" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Federated Learning (FL) lets multiple data owners collaborate in training a global model without any violation of data privacy, which is a crucial requirement for enhancing users’ trust in Artificial Intelligence (AI) systems. Despite the significant momentum recently gained by the FL paradigm, most of the existing approaches in the field neglect another key pillar for the trustworthiness of AI systems, namely explainability. In this paper, we propose a novel approach for FL of fuzzy regression trees (FRTs), which are generally acknowledged as highly interpretable by-design models. The proposed FL procedure is designed for the scenario of horizontally partitioned data and is based on the transmission of aggregated statistics from the clients to a central server for the tree induction procedure. It is shown that the proposed approach faithfully approximates the ideal case in which the tree induction algorithm is applied on the union of all local datasets, while still ensuring privacy preservation. Furthermore, the FL approach brings benefits, in terms of generalization capability, compared to the local learning setting in which each participant learns its own FRT based only on the private, local, dataset. The adoption of linear models in the leaf nodes ensures a competitive level of performance, as assessed by an extensive experimental campaign on benchmark datasets. The analysis of the results covers both the aspects of accuracy and interpretability of FRT. Finally, we discuss the application of the proposed federated FRT to the task of Quality of Experience forecasting in an automotive case-study.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">inffus2025</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bárcena, J. L. Corcuera and Ducange, P. and Marcelloni, F. and Renda, A.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Increasing trust in AI through privacy preservation and model explainability: Federated Learning of Fuzzy Regression Trees}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Information Fusion}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{113}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{INFFUS}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.inffus.2024.102598}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S1566253524003762}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S1566253524003762}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/Unipisa/FederatedFuzzyRegressionTree}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{inffus2025.pdf}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">order</span> <span class="p">=</span> <span class="s">{2025-01}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">MACHLEARN</abbr>
    
  
  </div>

  <div id="Ducange2026" class="col-sm-8">
    
      <div class="title">Federated SHAP: Privacy-Preserving and Consistent Post-hoc Explainability in Federated Learning</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.it/citations?user=HCgZqXEAAAAJ&hl=it" target="_blank">Ducange, P.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.it/citations?hl=it&user=_EkQr2QAAAAJ" target="_blank">Marcelloni, F.</a>,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Miglionico, G.C.,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  <a href="https://scholar.google.it/citations?user=13nYgdUAAAAJ&hl=it" target="_blank">Renda, A.</a>,
                
              
            
          
        
          
          
          
          
            
              
                
                
          
          
          
            
              
                
                  and <a href="https://scholar.google.it/citations?hl=it&user=qLBgBmwAAAAJ" target="_blank">Ruffini, F.</a>
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2026
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://doi.org/10.1007/s10994-025-06956-1" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
      
      <a href="/assets/pdf/ML2026.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The widespread adoption of Artificial Intelligence in everyday activities highlights a growing and urgent need for trustworthiness. Designing trustworthy AI systems requires addressing key technical challenges, including ensuring data privacy and model explainability. Federated Learning (FL) is a widely adopted paradigm to preserve data privacy in collaborative learning scenarios, while post-hoc methods are commonly applied to enhance the explainability of opaque AI-based models. In this paper, we propose a novel approach, called Federated SHAP, to simultaneously address privacy and explainability. Specifically, we leverage the SHapley Additive exPlanations (SHAP) method to provide post-hoc explanations of Neural Networks trained through FL. SHAP relies on a representative background dataset; however, constructing such a dataset in the FL setting is particularly challenging since raw data distributed across multiple clients cannot be shared directly due to strict privacy requirements. To address this challenge, we propose two tailored strategies depending on the data type: for tabular data, we adopt a Federated Fuzzy C-Means clustering algorithm to collaboratively summarize the distributed datasets into a suitable background dataset; for image data, we introduce a Federated Generative Adversarial Network (GAN) to synthesize representative background instances. A comprehensive experimental evaluation demonstrates the effectiveness and robustness of our proposed approaches, comparing them against several baseline and alternative strategies in terms of both representativeness and quality of generated explanations. Compared to baselines employing randomly generated representative background datasets, our approach reduces the discrepancy of SHAP explanations by up to three times on tabular data and two times on image data (depending on the test case involved), when measured against the centralized SHAP values computed using the full training set as background dataset.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Ducange2026</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ducange, P. and Marcelloni, F. and Miglionico, G.C. and Renda, A. and Ruffini, F.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Federated SHAP: Privacy-Preserving and Consistent Post-hoc Explainability in Federated Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2026}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Machine Learning}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{115}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s10994-025-06956-1}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s10994-025-06956-1}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.scopus.com/inward/record.uri?eid=2-s2.0-105027956425&amp;doi=10.1007%2fs10994-025-06956-1&amp;partnerID=40&amp;md5=1015300be44e6ea6e07c9aeaf9718355}</span><span class="p">,</span>
  <span class="na">type</span> <span class="p">=</span> <span class="s">{Article}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{ML2026.pdf}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{MACHLEARN}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>
</div>

    

    
    <div class="social">
      <div class="contact-icons">
        
<a href="https://orcid.org/0000-0002-0482-5048" target="_blank" title="ORCID"><i class="ai ai-orcid"></i></a>
<a href="https://scholar.google.com/citations?user=13nYgdUAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>















      </div>
      <div class="contact-note"></div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2026 Alessandro  Renda.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
